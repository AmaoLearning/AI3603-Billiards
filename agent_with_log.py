"""
agent.py - Agent å†³ç­–æ¨¡å—

å®šä¹‰ Agent åŸºç±»å’Œå…·ä½“å®ç°ï¼š
- Agent: åŸºç±»ï¼Œå®šä¹‰å†³ç­–æ¥å£
- BasicAgent: åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„å‚è€ƒå®ç°
- NewAgent: å­¦ç”Ÿè‡ªå®šä¹‰å®ç°æ¨¡æ¿
- analyze_shot_for_reward: å‡»çƒç»“æœè¯„åˆ†å‡½æ•°
"""

import math
import pooltool as pt
import numpy as np
from pooltool.objects import PocketTableSpecs, Table, TableType
import copy
import os
from datetime import datetime
import random
import logging
import torch
# from poolagent.pool import Pool as CuetipEnv, State as CuetipState
# from poolagent import FunctionAgent

from bayes_opt import BayesianOptimization, SequentialDomainReductionTransformer
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern
from train.train_fast import AimNet
from utils import calculate_ghost_ball_params, get_pockets, evaluate_state

import functools


logger = logging.getLogger("evaluate")


def analyze_shot_for_reward(shot: pt.System, last_state: dict, player_targets: list):
    """
    åˆ†æå‡»çƒç»“æœå¹¶è®¡ç®—å¥–åŠ±åˆ†æ•°
    
    å‚æ•°ï¼š
        shot: å·²å®Œæˆç‰©ç†æ¨¡æ‹Ÿçš„ System å¯¹è±¡
        last_state: å‡»çƒå‰çš„çƒçŠ¶æ€ï¼Œ{ball_id: Ball}
        player_targets: å½“å‰ç©å®¶ç›®æ ‡çƒIDï¼Œ['1', '2', ...]
    
    è¿”å›ï¼š
        float: å¥–åŠ±åˆ†æ•°
            +50/çƒï¼ˆå·±æ–¹è¿›çƒï¼‰, +100ï¼ˆåˆæ³•é»‘8ï¼‰, +10ï¼ˆåˆæ³•æ— è¿›çƒï¼‰
            -100ï¼ˆç™½çƒè¿›è¢‹ï¼‰, -150ï¼ˆéæ³•é»‘8ï¼‰, -30ï¼ˆé¦–çƒ/ç¢°åº“çŠ¯è§„ï¼‰
    """
    
    # 1. åŸºæœ¬åˆ†æ
    new_pocketed = [bid for bid, b in shot.balls.items() if b.state.s == 4 and last_state[bid].state.s != 4]
    
    own_pocketed = [bid for bid in new_pocketed if bid in player_targets]
    enemy_pocketed = [bid for bid in new_pocketed if bid not in player_targets and bid not in ["cue", "8"]]
    
    cue_pocketed = "cue" in new_pocketed
    eight_pocketed = "8" in new_pocketed

    # 2. åˆ†æé¦–çƒç¢°æ’
    first_contact_ball_id = None
    foul_first_hit = False
    
    for e in shot.events:
        et = str(e.event_type).lower()
        ids = list(e.ids) if hasattr(e, 'ids') else []
        if ('cushion' not in et) and ('pocket' not in et) and ('cue' in ids):
            other_ids = [i for i in ids if i != 'cue']
            if other_ids:
                first_contact_ball_id = other_ids[0]
                break
    
    if first_contact_ball_id is None:
        if len(last_state) > 2:  # åªæœ‰ç™½çƒå’Œ8å·çƒæ—¶ä¸ç®—çŠ¯è§„
             foul_first_hit = True
    else:
        remaining_own_before = [bid for bid in player_targets if last_state[bid].state.s != 4]
        opponent_plus_eight = [bid for bid in last_state.keys() if bid not in player_targets and bid not in ['cue']]
        if ('8' not in opponent_plus_eight):
            opponent_plus_eight.append('8')
            
        if len(remaining_own_before) > 0 and first_contact_ball_id in opponent_plus_eight:
            foul_first_hit = True
    
    # 3. åˆ†æç¢°åº“
    cue_hit_cushion = False
    target_hit_cushion = False
    foul_no_rail = False
    
    for e in shot.events:
        et = str(e.event_type).lower()
        ids = list(e.ids) if hasattr(e, 'ids') else []
        if 'cushion' in et:
            if 'cue' in ids:
                cue_hit_cushion = True
            if first_contact_ball_id is not None and first_contact_ball_id in ids:
                target_hit_cushion = True

    if len(new_pocketed) == 0 and first_contact_ball_id is not None and (not cue_hit_cushion) and (not target_hit_cushion):
        foul_no_rail = True
        
    # è®¡ç®—å¥–åŠ±åˆ†æ•°
    score = 0
    
    if cue_pocketed and eight_pocketed:
        score -= 150
    elif cue_pocketed:
        score -= 100
    elif eight_pocketed:
        is_targeting_eight_ball_legally = (len(player_targets) == 1 and player_targets[0] == "8")
        score += 100 if is_targeting_eight_ball_legally else -150
            
    if foul_first_hit:
        score -= 30
    if foul_no_rail:
        score -= 30
        
    score += len(own_pocketed) * 50
    score -= len(enemy_pocketed) * 20
    
    if score == 0 and not cue_pocketed and not eight_pocketed and not foul_first_hit and not foul_no_rail:
        score = 10
        
    return score

class Agent():
    """Agent åŸºç±»"""
    def __init__(self):
        pass
    
    def decision(self, *args, **kwargs):
        """å†³ç­–æ–¹æ³•ï¼ˆå­ç±»éœ€å®ç°ï¼‰
        
        è¿”å›ï¼šdict, åŒ…å« 'V0', 'phi', 'theta', 'a', 'b'
        """
        pass
    
    def _random_action(self,):
        """ç”Ÿæˆéšæœºå‡»çƒåŠ¨ä½œ
        
        è¿”å›ï¼šdict
            V0: [0.5, 8.0] m/s
            phi: [0, 360] åº¦
            theta: [0, 90] åº¦
            a, b: [-0.5, 0.5] çƒåŠå¾„æ¯”ä¾‹
        """
        action = {
            'V0': round(random.uniform(0.5, 8.0), 2),   # åˆé€Ÿåº¦ 0.5~8.0 m/s
            'phi': round(random.uniform(0, 360), 2),    # æ°´å¹³è§’åº¦ (0Â°~360Â°)
            'theta': round(random.uniform(0, 90), 2),   # å‚ç›´è§’åº¦
            'a': round(random.uniform(-0.5, 0.5), 3),   # æ†å¤´æ¨ªå‘åç§»ï¼ˆå•ä½ï¼šçƒåŠå¾„æ¯”ä¾‹ï¼‰
            'b': round(random.uniform(-0.5, 0.5), 3)    # æ†å¤´çºµå‘åç§»
        }
        return action



class BasicAgent(Agent):
    """åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ™ºèƒ½ Agent"""
    
    def __init__(self, target_balls=None):
        """åˆå§‹åŒ– Agent
        
        å‚æ•°ï¼š
            target_balls: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨
        """
        super().__init__()
        
        # æœç´¢ç©ºé—´
        self.pbounds = {
            'V0': (0.5, 8.0),
            'phi': (0, 360),
            'theta': (0, 90), 
            'a': (-0.5, 0.5),
            'b': (-0.5, 0.5)
        }
        
        # ä¼˜åŒ–å‚æ•°
        self.INITIAL_SEARCH = 20
        self.OPT_SEARCH = 10
        self.ALPHA = 1e-2
        
        # æ¨¡æ‹Ÿå™ªå£°ï¼ˆå¯è°ƒæ•´ä»¥æ”¹å˜è®­ç»ƒéš¾åº¦ï¼‰
        self.noise_std = {
            'V0': 0.1,
            'phi': 0.1,
            'theta': 0.1,
            'a': 0.003,
            'b': 0.003
        }
        self.enable_noise = False
        
        logger.info("BasicAgent (Smart, pooltool-native) å·²åˆå§‹åŒ–ã€‚")

    
    def _create_optimizer(self, reward_function, seed):
        """åˆ›å»ºè´å¶æ–¯ä¼˜åŒ–å™¨
        
        å‚æ•°ï¼š
            reward_function: ç›®æ ‡å‡½æ•°ï¼Œ(V0, phi, theta, a, b) -> score
            seed: éšæœºç§å­
        
        è¿”å›ï¼š
            BayesianOptimizationå¯¹è±¡
        """
        gpr = GaussianProcessRegressor(
            kernel=Matern(nu=2.5),
            alpha=self.ALPHA,
            n_restarts_optimizer=10,
            random_state=seed
        )
        
        bounds_transformer = SequentialDomainReductionTransformer(
            gamma_osc=0.8,
            gamma_pan=1.0
        )
        
        optimizer = BayesianOptimization(
            f=reward_function,
            pbounds=self.pbounds,
            random_state=seed,
            verbose=0,
            bounds_transformer=bounds_transformer
        )
        optimizer._gp = gpr
        
        return optimizer


    def decision(self, balls=None, my_targets=None, table=None):
        """ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æœç´¢æœ€ä½³å‡»çƒå‚æ•°
        
        å‚æ•°ï¼š
            balls: çƒçŠ¶æ€å­—å…¸ï¼Œ{ball_id: Ball}
            my_targets: ç›®æ ‡çƒIDåˆ—è¡¨ï¼Œ['1', '2', ...]
            table: çƒæ¡Œå¯¹è±¡
        
        è¿”å›ï¼š
            dict: å‡»çƒåŠ¨ä½œ {'V0', 'phi', 'theta', 'a', 'b'}
                å¤±è´¥æ—¶è¿”å›éšæœºåŠ¨ä½œ
        """
        if balls is None:
            logger.info("[BasicAgent] Agent decisionå‡½æ•°æœªæ”¶åˆ°ballså…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚")
            return self._random_action()
        try:
            
            # ä¿å­˜ä¸€ä¸ªå‡»çƒå‰çš„çŠ¶æ€å¿«ç…§ï¼Œç”¨äºå¯¹æ¯”
            last_state_snapshot = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}

            remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
            if len(remaining_own) == 0:
                my_targets = ["8"]
                logger.info("[BasicAgent] æˆ‘çš„ç›®æ ‡çƒå·²å…¨éƒ¨æ¸…ç©ºï¼Œè‡ªåŠ¨åˆ‡æ¢ç›®æ ‡ä¸ºï¼š8å·çƒ")

            # 1.åŠ¨æ€åˆ›å»ºâ€œå¥–åŠ±å‡½æ•°â€ (Wrapper)
            # è´å¶æ–¯ä¼˜åŒ–å™¨ä¼šè°ƒç”¨æ­¤å‡½æ•°ï¼Œå¹¶ä¼ å…¥å‚æ•°
            def reward_fn_wrapper(V0, phi, theta, a, b):
                # åˆ›å»ºä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿçš„æ²™ç›’ç³»ç»Ÿ
                sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
                sim_table = copy.deepcopy(table)
                cue = pt.Cue(cue_ball_id="cue")

                shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
                
                try:
                    if self.enable_noise:
                        V0_noisy = V0 + np.random.normal(0, self.noise_std['V0'])
                        phi_noisy = phi + np.random.normal(0, self.noise_std['phi'])
                        theta_noisy = theta + np.random.normal(0, self.noise_std['theta'])
                        a_noisy = a + np.random.normal(0, self.noise_std['a'])
                        b_noisy = b + np.random.normal(0, self.noise_std['b'])
                        
                        V0_noisy = np.clip(V0_noisy, 0.5, 8.0)
                        phi_noisy = phi_noisy % 360
                        theta_noisy = np.clip(theta_noisy, 0, 90)
                        a_noisy = np.clip(a_noisy, -0.5, 0.5)
                        b_noisy = np.clip(b_noisy, -0.5, 0.5)
                        
                        shot.cue.set_state(V0=V0_noisy, phi=phi_noisy, theta=theta_noisy, a=a_noisy, b=b_noisy)
                    else:
                        shot.cue.set_state(V0=V0, phi=phi, theta=theta, a=a, b=b)
                    
                    # å…³é”®ï¼šä½¿ç”¨ pooltool ç‰©ç†å¼•æ“ (ä¸–ç•ŒA)
                    pt.simulate(shot, inplace=True)
                except Exception as e:
                    # æ¨¡æ‹Ÿå¤±è´¥ï¼Œç»™äºˆæå¤§æƒ©ç½š
                    return -500
                
                # ä½¿ç”¨æˆ‘ä»¬çš„â€œè£åˆ¤â€æ¥æ‰“åˆ†
                score = analyze_shot_for_reward(
                    shot=shot,
                    last_state=last_state_snapshot,
                    player_targets=my_targets
                )


                return score

            logger.info("[BasicAgent] æ­£åœ¨ä¸º Player (targets: %s) æœç´¢æœ€ä½³å‡»çƒ...", remaining_own)
            
            seed = np.random.randint(1e6)
            optimizer = self._create_optimizer(reward_fn_wrapper, seed)
            optimizer.maximize(
                init_points=self.INITIAL_SEARCH,
                n_iter=self.OPT_SEARCH
            )
            
            best_result = optimizer.max
            best_params = best_result['params']
            best_score = best_result['target']

            if best_score < 10:
                logger.info("[BasicAgent] æœªæ‰¾åˆ°å¥½çš„æ–¹æ¡ˆ (æœ€é«˜åˆ†: %.2f)ã€‚ä½¿ç”¨éšæœºåŠ¨ä½œã€‚", best_score)
                return self._random_action()
            action = {
                'V0': float(best_params['V0']),
                'phi': float(best_params['phi']),
                'theta': float(best_params['theta']),
                'a': float(best_params['a']),
                'b': float(best_params['b']),
            }

            logger.info(
                "[BasicAgent] å†³ç­– (å¾—åˆ†: %.2f): V0=%.2f, phi=%.2f, Î¸=%.2f, a=%.3f, b=%.3f",
                best_score,
                action['V0'],
                action['phi'],
                action['theta'],
                action['a'],
                action['b'],
            )
            return action

        except Exception as e:
            logger.error("[BasicAgent] å†³ç­–æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚åŸå› : %s", e)
            import traceback
            logger.exception(e)
            return self._random_action()

class NewAgent(Agent):
    """è‡ªå®šä¹‰ Agent æ¨¡æ¿ï¼ˆå¾…å­¦ç”Ÿå®ç°ï¼‰"""
    
    def __init__(self):
        model_path = os.path.join('train', 'checkpoints', 'aim_model.pth')
        #self.agent = HybridLearningAgent(model_path)
        # self.agent = MCTSAgent()
        self.agent = BayesMCTSAgent()
    
    def decision(self, balls=None, my_targets=None, table=None):
        """å†³ç­–æ–¹æ³•
        
        å‚æ•°ï¼š
            observation: (balls, my_targets, table)
        
        è¿”å›ï¼š
            dict: {'V0', 'phi', 'theta', 'a', 'b'}
        """
        return self.agent.decision(balls=balls, my_targets=my_targets, table=table)
    
    def method(self):
        """
        å®é™…æ‰€ç”¨æ–¹æ³•çš„åç§°
        """
        return self.agent.__class__.__name__

class MCTSAgent(Agent):
    """
    MCTS-Lite Agent
    ç‰¹ç‚¹ï¼š
    1. å‡ ä½•æ±‚è§£ + å¾®è°ƒæ¨¡æ‹Ÿ
    2. åœ¨è¯„ä¼°å†³ç­–æ—¶å¤šçœ‹ä¸€æ­¥
    3. æ²¡æœ‰å­¦ä¹ è¿‡ç¨‹, æ¯”è¾ƒçœæ—¶

    æˆç»©: 29.0/40.0, 0.725
          æ¢ç”¨analyze_shot_for_rewardåä¸º 32.0/40.0, 0.800
          èµ°ä½è¯„åˆ†ç‰ˆæœ¬1 25.0/40.0, 0.625
          å®Œå…¨ä¸æˆªæ–­ç‰ˆæœ¬ 22.0/40.0, 0.550
          è§’åº¦æ”¾å®½åˆ°90/candidatesæ”¾å¤šåˆ°6ä¸ªç‰ˆæœ¬ 20.0/40.0, 0.500
    """
    def __init__(self):
        super().__init__()
        logger.info("ImprovedMCTSAgent å·²åˆå§‹åŒ– - åŒ…å«é˜²å®ˆé€»è¾‘ä¸å¾®è°ƒç„å‡†")

    def _generate_safety_shot(self, balls, candidates):
        """
        é˜²å®ˆç­–ç•¥ï¼šå½“æ²¡æœ‰å¥½æœºä¼šæ—¶ï¼Œè½»è½»ç¢°ä¸€ä¸‹ç¦»å¾—æœ€è¿‘çš„çƒï¼Œé¿å…çŠ¯è§„
        """
        logger.info("[MCTSAgent] å¯åŠ¨é˜²å®ˆæ¨¡å¼ (Safety Mode)")
        cue_pos = balls['cue'].state.rvw[0]
        min_dist = float('inf')
        best_target = None
        
        # æ‰¾æœ€è¿‘çš„è‡ªå·±çš„çƒ
        for bid in candidates:
            obj_pos = balls[bid].state.rvw[0]
            dist = np.linalg.norm(np.array(obj_pos[:2]) - np.array(cue_pos[:2]))
            if dist < min_dist:
                min_dist = dist
                best_target = bid
        
        if best_target:
            obj_pos = balls[best_target].state.rvw[0]
            dx = obj_pos[0] - cue_pos[0]
            dy = obj_pos[1] - cue_pos[1]
            phi = np.degrees(np.arctan2(dy, dx)) % 360
            # æè½»çš„åŠ›åº¦ï¼Œåªè¦ç¢°åˆ°å°±è¡Œ
            logger.info(f'[MCTSAgent] è½»è½»è§¦ç¢°å·±æ–¹çƒ {best_target}')
            return {'V0': 0.8, 'phi': phi, 'theta': 0, 'a': 0, 'b': 0}
        
        return self._random_action()

    def decision(self, balls=None, my_targets=None, table=None):
        if balls is None:
            return self._random_action()
        
        cue_ball = balls['cue']
        cue_pos = cue_ball.state.rvw[0]
        R = cue_ball.params.R

        last_state_snapshot = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
        # --- 1. ç”Ÿæˆå‡ ä½•å€™é€‰ (Candidates) ---
        candidates = [] 
        remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
        if not remaining_own: remaining_own = ['8']

        logger.info("[MCTSAgent] æ­£åœ¨ä¸º Player (targets: %s) æœç´¢æœ€ä½³å‡»çƒ...", remaining_own)

        for ball_id in remaining_own:
            obj_pos = balls[ball_id].state.rvw[0]
            for pid, pocket in table.pockets.items():
                phi_ideal, cut_angle, dist = calculate_ghost_ball_params(cue_pos, obj_pos, pocket.center, R)
                
                # åªæœ‰éå¸¸éš¾æ‰“çš„çƒæ‰ä¼šè¢«è¿‡æ»¤ (é˜ˆå€¼ 85åº¦)
                if abs(cut_angle) > 85: continue
                
                candidates.append({
                    'target_id': ball_id,
                    'phi_center': phi_ideal,
                    'cut_angle': cut_angle,
                    'distance': dist
                })

        # å¦‚æœçœŸçš„æ²¡æœ‰è¿›æ”»æœºä¼šï¼Œæ‰§è¡Œé˜²å®ˆ
        if not candidates:
            logger.info("[MCTSAgent] æ— å‡ ä½•è¿›æ”»çº¿è·¯ï¼Œå°è¯•é˜²å®ˆã€‚")
            return self._generate_safety_shot(balls, remaining_own)

        # æ’åºï¼šä¼˜å…ˆè€ƒè™‘åˆ‡è§’å°ã€è·ç¦»è¿‘çš„çƒ
        candidates.sort(key=lambda x: x['cut_angle'] + x['distance']*10)
        top_candidates = candidates[:4] # åªçœ‹å‰4ä¸ªæœ€å¥½çš„é€‰æ‹©

        best_action = None
        best_score = -float('inf')
        best_tag = ""

        # --- 2. æ¨¡æ‹Ÿä¸å¾®è°ƒ (Simulation) ---
        logger.info("[MCTSAgent] è¯„ä¼° %d ä¸ªè¿›æ”»çº¿è·¯...", len(top_candidates))
        
        for cand in top_candidates: # åˆ°åªå‰©8æ—¶ç»å¸¸åªæœ‰1ä¸ªcandï¼Œè¿™è¯´æ˜ç™½çƒä½ç½®ä¸å¥½
            # å¾®è°ƒé€»è¾‘ï¼šä¸ä»…å°è¯•ç†è®ºè§’åº¦ï¼Œè¿˜è¦å°è¯•å·¦å³åå·®
            # ç‰©ç†å¼•æ“ä¸­ï¼Œçƒçš„ç¢°æ’ä¼šæœ‰åå·®ï¼Œå¿…é¡»é€šè¿‡å¾®è°ƒæ¥ä¿®æ­£
            phi_offsets = [0, -0.5, 0.5, -1.0, 1.0] 
            speeds = [0.8, 2.0, 4.0, 6.5] # è½»æ¨ã€æ…¢ã€ä¸­ã€å¿«
            
            for V0 in speeds:
                for offset in phi_offsets:
                    phi_try = cand['phi_center'] + offset
                    
                    # æ„å»ºæ¨¡æ‹Ÿç¯å¢ƒ
                    sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
                    sim_table = copy.deepcopy(table)
                    cue = pt.Cue(cue_ball_id="cue")
                    cue.set_state(V0=V0, phi=phi_try, theta=0, a=0, b=0)
                    shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
                    
                    try:
                        pt.simulate(shot, inplace=True)
                        score = evaluate_state(shot, last_state_snapshot, my_targets)
                        
                        if score > best_score:
                            best_score = score
                            best_action = {'V0': V0, 'phi': phi_try, 'theta': 0, 'a': 0, 'b': 0}
                            # å¦‚æœæ‰¾åˆ°äº†å¿…è¿›çƒä¸”èµ°ä½ä¸é”™çš„è§£ï¼Œå¯ä»¥æå‰å‰ªæï¼Œä¹Ÿç›¸å½“äºå€¾å‘äºé€Ÿåº¦æ›´å°çš„åŠ¨ä½œ
                            if score >= 60: 
                                logger.info("[MCTSAgent] æ‰¾åˆ°ç»ä½³çº¿è·¯ï¼å†³ç­–: V0=%.1f, phi=%.1f (ExpScore:%.1f)",
                                                best_action['V0'],
                                                best_action['phi'],
                                                best_score,)
                                return best_action
                                
                    except Exception as e:
                        # æ‰“å°é”™è¯¯ä½†ä¸ä¸­æ–­ç¨‹åº
                        logger.error("[MCTSAgent ERROR] Sim failed: %s", e)
                        continue

        if (best_action is None) or (best_score < 0): # æ›´æ¿€è¿›åœ°é‡‡å–é˜²å®ˆç­–ç•¥
            logger.info("[MCTSAgent] æ¨¡æ‹Ÿåæœªå‘ç°å¯è¡Œè¿›æ”»æ–¹æ¡ˆï¼Œè½¬ä¸ºé˜²å®ˆã€‚")
            return self._generate_safety_shot(balls, remaining_own)
            
        logger.info(
            "[MCTSAgent] å†³ç­–: V0=%.1f, phi=%.1f (ExpScore:%.1f)",
            best_action['V0'],
            best_action['phi'],
            best_score,
        )
        return best_action

    def _random_action(self):
        return {'V0': 1.0, 'phi': np.random.uniform(0,360), 'theta':0, 'a':0, 'b':0}

class BankAgent(Agent):
    """
    BankAgent (MCTS + Bank Shots)
    ç‰¹ç‚¹ï¼š
    1. ç»§æ‰¿äº† MCTSAgent çš„å‡ ä½•æ±‚è§£ + å¾®è°ƒæ¨¡æ‹Ÿèƒ½åŠ›
    2. æ–°å¢ï¼šç¿»è¢‹ (Bank Shot) è·¯å¾„è§„åˆ’èƒ½åŠ›
    3. èƒ½å¤Ÿè¯†åˆ«ç›´æ‰“å›°éš¾çš„å±€é¢ï¼Œè‡ªåŠ¨å¯»æ‰¾æ’åº“è§£æ³•
    """
    def __init__(self):
        super().__init__()
        logger.info("BankAgent å·²åˆå§‹åŒ– - å…·å¤‡ç¿»è¢‹æ”»å‡»èƒ½åŠ›")

    def _get_table_rails(self, table):
        """è·å–4ä¸ªåº“è¾¹çš„åæ ‡ä½ç½®"""
        # table.w æ˜¯å®½ (yè½´æ–¹å‘), table.l æ˜¯é•¿ (xè½´æ–¹å‘)
        # å‡è®¾çƒæ¡Œä¸­å¿ƒåœ¨ (0,0)
        right = table.l / 2
        left = -table.l / 2
        top = table.w / 2
        bottom = -table.w / 2
        return {'left': left, 'right': right, 'top': top, 'bottom': bottom}

    def _get_virtual_pocket(self, pocket_pos, rail_name, rails):
        """è®¡ç®—è™šæ‹Ÿè¢‹å£åæ ‡ (é•œåƒç‚¹)"""
        px, py = pocket_pos[0], pocket_pos[1]
        
        if rail_name == 'top':   # y = top, é•œåƒç‚¹ y' = 2*top - y
            return np.array([px, 2 * rails['top'] - py, 0])
        elif rail_name == 'bottom':
            return np.array([px, 2 * rails['bottom'] - py, 0])
        elif rail_name == 'left': # x = left, é•œåƒç‚¹ x' = 2*left - x
            return np.array([2 * rails['left'] - px, py, 0])
        elif rail_name == 'right':
            return np.array([2 * rails['right'] - px, py, 0])
        return None

    def _generate_safety_shot(self, balls, my_targets):
        """é˜²å®ˆç­–ç•¥"""
        logger.info("[BankAgent] å¯åŠ¨é˜²å®ˆæ¨¡å¼ (Safety Mode)")
        cue_pos = balls['cue'].state.rvw[0]
        min_dist = float('inf')
        best_target = None
        
        candidates = [b for b in my_targets if balls[b].state.s != 4]
        if not candidates: candidates = ['8']
        
        for bid in candidates:
            obj_pos = balls[bid].state.rvw[0]
            dist = np.linalg.norm(np.array(obj_pos[:2]) - np.array(cue_pos[:2]))
            if dist < min_dist:
                min_dist = dist
                best_target = bid
        
        if best_target:
            obj_pos = balls[best_target].state.rvw[0]
            dx = obj_pos[0] - cue_pos[0]
            dy = obj_pos[1] - cue_pos[1]
            phi = np.degrees(np.arctan2(dy, dx)) % 360
            return {'V0': 0.8, 'phi': phi, 'theta': 0, 'a': 0, 'b': 0}
        
        return self._random_action()

    def _generate_bank_candidates(self, balls, my_targets, table, cue_pos, R):
        """ç”Ÿæˆç¿»è¢‹å‡»çƒå€™é€‰"""
        candidates = []
        rails = self._get_table_rails(table)
        
        remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
        if not remaining_own: remaining_own = ['8']

        for ball_id in remaining_own:
            obj_pos = balls[ball_id].state.rvw[0]
            
            # éå†4æ¡åº“è¾¹
            for rail_name in ['top', 'bottom', 'left', 'right']:
                for pid, pocket in table.pockets.items():
                    # è®¡ç®—è™šæ‹Ÿè¢‹å£
                    virtual_pos = self._get_virtual_pocket(pocket.center, rail_name, rails)
                    
                    # å‡ ä½•è®¡ç®—ï¼šæŠŠè™šæ‹Ÿè¢‹å£å½“åšç›®æ ‡
                    phi_ideal, cut_angle, dist_cue_obj = calculate_ghost_ball_params(
                        cue_pos, obj_pos, virtual_pos, R
                    )
                    
                    # ç¿»è¢‹éš¾åº¦è¾ƒå¤§ï¼Œåˆ‡è§’é˜ˆå€¼è®¾ä½ä¸€ç‚¹ (å¦‚ 60åº¦)
                    if abs(cut_angle) > 60: continue
                    
                    # ä¼°ç®—æ€»è·ç¦»ï¼šæ¯çƒ->ç›®æ ‡çƒ + ç›®æ ‡çƒ->è™šæ‹Ÿè¢‹å£
                    dist_obj_virtual = np.linalg.norm(virtual_pos - obj_pos)
                    total_dist = dist_cue_obj + dist_obj_virtual
                    
                    candidates.append({
                        'type': 'bank', # æ ‡è®°ç±»å‹
                        'target_id': ball_id,
                        'phi_center': phi_ideal,
                        'cut_angle': cut_angle,
                        'distance': total_dist,
                        'rail': rail_name,
                        'pocket_id': pid
                    })
        return candidates

    def decision(self, balls=None, my_targets=None, table=None):
        if balls is None: return self._random_action()
        
        cue_ball = balls['cue']
        cue_pos = cue_ball.state.rvw[0]
        R = cue_ball.params.R

        # --- 1. ç”Ÿæˆç›´æ‰“å€™é€‰ (Direct) ---
        candidates = [] 
        remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
        if not remaining_own: remaining_own = ['8']

        for ball_id in remaining_own:
            obj_pos = balls[ball_id].state.rvw[0]
            for pid, pocket in table.pockets.items():
                phi_ideal, cut_angle, dist = calculate_ghost_ball_params(cue_pos, obj_pos, pocket.center, R)
                
                if abs(cut_angle) > 85: continue
                
                candidates.append({
                    'type': 'direct',
                    'target_id': ball_id,
                    'phi_center': phi_ideal,
                    'cut_angle': cut_angle,
                    'distance': dist
                })

        # --- 2. ç”Ÿæˆç¿»è¢‹å€™é€‰ (Bank) ---
        bank_candidates = self._generate_bank_candidates(balls, my_targets, table, cue_pos, R)
        candidates.extend(bank_candidates)

        if not candidates:
            logger.info("[BankAgent] æ— å‡ ä½•è¿›æ”»çº¿è·¯ï¼Œå°è¯•é˜²å®ˆã€‚")
            return self._generate_safety_shot(balls, my_targets)

        # --- 3. æ··åˆæ’åº ---
        # ç•¥å¾®é™ä½ç¿»è¢‹æƒ©ç½šï¼Œé¼“åŠ±åœ¨ç›´æ‰“å›°éš¾æ—¶å°è¯•ç¿»è¢‹
        def sort_key(c):
            penalty = 0 if c['type'] == 'direct' else 25
            return c['cut_angle'] + c['distance']*10 + penalty

        candidates.sort(key=sort_key)
        top_candidates = candidates[:5]  # åªå…³æ³¨å‰5ä¸ªæœºä¼š

        logger.info(
            "[BankAgent] è¯„ä¼° %d ä¸ªçº¿è·¯ (å« %d ä¸ªç¿»è¢‹)...",
            len(top_candidates),
            sum(1 for c in top_candidates if c['type']=='bank'),
        )

        best_action = None
        best_score = 0  # åªæ¥å—å¾—åˆ†>0çš„æ–¹æ¡ˆ
        best_tag = ""

        # --- 4. æ¨¡æ‹Ÿä¸é«˜ç²¾åº¦å¾®è°ƒ ---
        for cand in top_candidates:
            # é«˜å¯†åº¦è§’åº¦å¾®è°ƒï¼šç›´æ‰“[-1.5,1.5]åˆ†21ä»½ï¼›ç¿»è¢‹[-2.5,2.5]åˆ†31ä»½
            phi_offsets = np.linspace(-1.5, 1.5, 21)
            
            if cand['type'] == 'bank':
                phi_offsets = np.linspace(-2.5, 2.5, 31)
                base_speeds = [4.0, 6.0, 8.0]
            else:
                base_speeds = [2.5, 4.5, 6.5]
            
            for V0 in base_speeds:
                # å¦‚æœå·²æœ‰è¾ƒé«˜å¾—åˆ†ï¼Œå½“å‰çº¿è·¯ä¸å†å°è¯•æ›´å¤šåŠ›åº¦ä»¥èŠ‚çœæ—¶é—´
                if best_score > 80:
                    break

                for offset in phi_offsets:
                    phi_try = cand['phi_center'] + offset
                    
                    sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
                    sim_table = copy.deepcopy(table)
                    cue = pt.Cue(cue_ball_id="cue")
                    cue.set_state(V0=V0, phi=phi_try, theta=0, a=0, b=0)
                    shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
                    
                    try:
                        pt.simulate(shot, inplace=True)
                        score = evaluate_state(shot, my_targets, cand['target_id'])
                        
                        if score > best_score:
                            best_score = score
                            best_action = {'V0': V0, 'phi': phi_try, 'theta': 0, 'a': 0, 'b': 0}
                            best_tag = "[ç¿»è¢‹]" if cand['type'] == 'bank' else "[ç›´æ‰“]"

                            if score > 120:
                                logger.info("[BankAgent] é”å®š%sç»ä½³çº¿è·¯ï¼Score: %.1f", best_tag, score)
                                return best_action
                    except Exception:
                        continue

        if best_action is None:
            logger.info("[BankAgent] æ¨¡æ‹Ÿæ˜¾ç¤ºæ— è¿›çƒæœºä¼š (BestScore: %.1f)ï¼Œæ™ºèƒ½è½¬ä¸ºé˜²å®ˆã€‚", best_score)
            return self._generate_safety_shot(balls, my_targets)
            
        logger.info(
            "[BankAgent] å†³ç­–: V0=%.1f, phi=%.1f, score=%.1f %s",
            best_action['V0'],
            best_action['phi'],
            best_score,
            best_tag,
        )
        return best_action

    def _random_action(self):
        return {'V0': 1.0, 'phi': np.random.uniform(0,360), 'theta':0, 'a':0, 'b':0}

class HybridLearningAgent(Agent):
    """
    æ··åˆæ™ºèƒ½ä½“ï¼šç¥ç»ç½‘ç»œå¼•å¯¼ + å±€éƒ¨æœç´¢éªŒè¯
    ç­–ç•¥ï¼š
    1. ä½¿ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹åå·®ï¼Œå¤§å¹…ç¼©å°æœç´¢èŒƒå›´ã€‚
    2. åœ¨é¢„æµ‹å€¼é™„è¿‘è¿›è¡Œå¾®å°èŒƒå›´çš„æ¨¡æ‹ŸéªŒè¯ï¼ˆè§£å†³ç‰©ç†å™ªå£°ï¼‰ã€‚
    3. å¦‚æœè¿›æ”»æ¨¡æ‹Ÿå…¨éƒ¨å¤±è´¥ï¼Œä¸¥æ ¼æ‰§è¡Œé˜²å®ˆï¼ˆè§£å†³ä¹±æ‰“é—®é¢˜ï¼‰ã€‚
   
    æˆç»©ï¼šæ¢ç”¨analyze_shot_for_rewardå 23.0/40.0 0.575
    """
    def __init__(self, model_path='checkpoints/aim_model.pth'):
        super().__init__()
        self.model = AimNet()
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        try:
            # åŠ è½½æ¨¡å‹
            state_dict = torch.load(model_path, map_location=self.device)
            self.model.load_state_dict(state_dict)
            self.model.to(self.device)
            self.model.eval()
            logger.info(f"[HybridAgent] ç¥ç»ç½‘ç»œåŠ è½½æˆåŠŸ: {model_path}")
            self.use_nn = True
        except Exception as e:
            logger.info(f"[HybridAgent] æ¨¡å‹åŠ è½½å¤±è´¥ ({e})ï¼Œå›é€€åˆ°çº¯å‡ ä½•æœç´¢æ¨¡å¼ã€‚")
            self.use_nn = False

    def _predict_correction(self, cut_angle, distance, V0):
        """è°ƒç”¨ç¥ç»ç½‘ç»œé¢„æµ‹ä¿®æ­£é‡"""
        if not self.use_nn: return 0.0

        c_norm = cut_angle / 90.0
        d_norm = distance / 2.05
        v_norm = V0 / 8.0
        
        inputs = torch.tensor([[c_norm, d_norm, v_norm]], dtype=torch.float32).to(self.device)
        
        with torch.no_grad():
            delta = self.model(inputs).item()
        return delta

    def _generate_safety_shot(self, balls, my_targets):
        """é˜²å®ˆç­–ç•¥ï¼šå¿…é¡»ç¢°åº“"""
        logger.info("[HybridAgent] è¿›æ”»ä¸å¯è¡Œï¼Œåˆ‡æ¢å¼ºåŠ›é˜²å®ˆã€‚")
        cue_pos = balls['cue'].state.rvw[0]
        min_dist = float('inf')
        best_target = None
        
        candidates = [b for b in my_targets if balls[b].state.s != 4]
        if not candidates: candidates = ['8']
        
        # æ‰¾æœ€è¿‘çš„çƒ
        for bid in candidates:
            obj_pos = balls[bid].state.rvw[0]
            dist = np.linalg.norm(np.array(obj_pos[:2]) - np.array(cue_pos[:2]))
            if dist < min_dist:
                min_dist = dist
                best_target = bid
        
        if best_target:
            obj_pos = balls[best_target].state.rvw[0]
            dx = obj_pos[0] - cue_pos[0]
            dy = obj_pos[1] - cue_pos[1]
            phi = np.degrees(np.arctan2(dy, dx)) % 360
            # åŠ›åº¦ 3.0ï¼Œç¡®ä¿ç¢°åº“ä¸çŠ¯è§„
            return {'V0': 3.0, 'phi': phi, 'theta': 0, 'a': 0, 'b': 0}
        
        # å®åœ¨æ²¡åŠæ³•ï¼Œéšæœºæ‰“
        return {'V0': 1.0, 'phi': 0, 'theta':0, 'a':0, 'b':0}

    def decision(self, balls=None, my_targets=None, table=None):
        if balls is None: return self._generate_safety_shot(balls, my_targets)
        
        cue_ball = balls['cue']
        cue_pos = cue_ball.state.rvw[0]
        R = cue_ball.params.R

        
        last_state_snapshot = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
        # --- 1. ç­›é€‰å€™é€‰çƒ ---
        candidates = []
        remaining = [bid for bid in my_targets if balls[bid].state.s != 4]
        if not remaining: remaining = ['8']
        
        for ball_id in remaining:
            obj_pos = balls[ball_id].state.rvw[0]
            for pid, pocket in table.pockets.items():
                phi_geo, cut_angle, dist = calculate_ghost_ball_params(cue_pos, obj_pos, pocket.center, R)
                # ä¸¥æ ¼è¿‡æ»¤ > 85 åº¦çš„çƒ
                if abs(cut_angle) > 85: continue
                
                candidates.append({
                    'target_id': ball_id,
                    'phi_geo': phi_geo,
                    'cut_angle': cut_angle,
                    'distance': dist
                })
        
        # æ’åºï¼šä¼˜å…ˆåˆ‡è§’å°ã€è·ç¦»è¿‘
        candidates.sort(key=lambda x: x['cut_angle'] + x['distance']*10)
        top_candidates = candidates[:4] # åªçœ‹æœ€å¥½çš„4ä¸ª

        best_action = None
        best_score = 0 # ã€å…³é”®ä¿®å¤ã€‘: åˆå§‹åˆ†æ•°è®¾ä¸º0ï¼Œä»»ä½•è´Ÿåˆ†(æ²¡è¿›)éƒ½ä¸ä¼šè¢«é€‰ä¸­

        # --- 2. æ··åˆæœç´¢ (Neural Guide + Local Search) ---
        for cand in top_candidates:
            # å°è¯•å‡ ç§åŠ›åº¦
            speeds = [3.0, 5.0, 7.0]
            
            for V0 in speeds:
                # Step A: ç¥ç»ç½‘ç»œé¢„æµ‹åå·®
                delta_pred = self._predict_correction(cand['cut_angle'], cand['distance'], V0)
                phi_center = cand['phi_geo'] + delta_pred
                
                # Step B: å±€éƒ¨å¾®è°ƒ (Local Grid Search)
                # æ—¢ç„¶ç½‘ç»œå¯èƒ½æœ‰è¯¯å·®ï¼Œæˆ‘ä»¬åœ¨é¢„æµ‹å€¼å·¦å³ 0.5åº¦ å†…å†æ‰« 5 ä¸ªç‚¹
                # è¿™æ ·æ—¢åˆ©ç”¨äº†ç½‘ç»œçš„å…ˆéªŒï¼Œåˆè§£å†³äº†ç‰©ç†å™ªå£°
                offsets = np.linspace(-0.5, 0.5, 5) 
                
                for off in offsets:
                    phi_try = phi_center + off
                    
                    # æ¨¡æ‹Ÿ
                    sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
                    sim_table = copy.deepcopy(table)
                    cue = pt.Cue(cue_ball_id="cue")
                    cue.set_state(V0=V0, phi=phi_try, theta=0, a=0, b=0)
                    shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
                    
                    try:
                        pt.simulate(shot, inplace=True)
                        score = evaluate_state(shot, last_state_snapshot, my_targets)
                        
                        # å¦‚æœæ˜¯å¥½ç»“æœ
                        if score > best_score:
                            best_score = score
                            best_action = {'V0': V0, 'phi': phi_try, 'theta': 0, 'a': 0, 'b': 0}
                            
                            # æå‰å‰ªæï¼šå¦‚æœå·²ç»ç¨³è¿›çƒäº†ï¼Œä¸ç”¨å†æœäº†
                            if score > 80: 
                                logger.info(f"[Hybrid] ğŸ¯ å‘½ä¸­! NNå:{delta_pred:.2f} | å¾®è°ƒ:{off:.2f} | Score:{score:.1f}")
                                return best_action
                                
                    except: continue

        # --- 3. å†³ç­– ---
        if best_action is not None and best_score > 0:
            logger.info(f"[Hybrid] å†³ç­–: V0={best_action['V0']:.1f}, phi={best_action['phi']:.1f} (ExpScore:{best_score:.1f})")
            return best_action
        
        # å¦‚æœæ¨¡æ‹Ÿäº†ä¸€åœˆï¼Œåˆ†æ•°å…¨æ˜¯ -50 æˆ– -1000ï¼Œè¯´æ˜æ ¹æœ¬è¿›ä¸å»
        # ã€å…³é”®ä¿®å¤ã€‘: ç»å¯¹ä¸é€‰é‚£äº› -50 çš„åŠ¨ä½œï¼Œè½¬ä¸ºé˜²å®ˆ
        logger.info(f"[Hybrid] è¿›æ”»æ¨¡æ‹Ÿå…¨å¤±è´¥ (BestScore: {best_score})ï¼Œè½¬ä¸ºé˜²å®ˆã€‚")
        return self._generate_safety_shot(balls, my_targets)

class BayesMCTSAgent(BasicAgent):
    """åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ™ºèƒ½MCTS Agent"""
    
    def __init__(self, target_balls=None):
        """åˆå§‹åŒ– Agent
        
        å‚æ•°ï¼š
            target_balls: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨
        """
        super().__init__()
        
        # æœç´¢ç©ºé—´
        self.pbounds = {
            'V0': (0.5, 8.0),
            'd_phi': (-5, 5),
            'theta': (0, 90), 
            'a': (-0.5, 0.5),
            'b': (-0.5, 0.5)
        }
        
        # ä¼˜åŒ–å‚æ•°
        self.INITIAL_SEARCH = 20
        self.OPT_SEARCH = 10
        self.ALPHA = 1e-2
        
        # æ¨¡æ‹Ÿå™ªå£°ï¼ˆå¯è°ƒæ•´ä»¥æ”¹å˜è®­ç»ƒéš¾åº¦ï¼‰
        self.noise_std = {
            'V0': 0.1,
            'd_phi': 0.1,
            'theta': 0.1,
            'a': 0.003,
            'b': 0.003
        }
        self.enable_noise = False
        
        logger.info("[BayesMCTS] (Smart, pooltool-native) å·²åˆå§‹åŒ–ã€‚")
    
    def _evaluate_action(self, V0, d_phi, theta, a, b, base_phi, balls, table, my_targets, last_state_snapshot):
        # 1. è¿˜åŸç»å¯¹è§’åº¦
        actual_phi = base_phi + d_phi
        
        sim_balls = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}
        sim_table = copy.deepcopy(table)
        cue = pt.Cue(cue_ball_id="cue")
        
        # 2. è®¾ç½®çŠ¶æ€
        sim_shot = pt.System(table=sim_table, balls=sim_balls, cue=cue)
        sim_shot.cue.set_state(V0=V0, phi=actual_phi, theta=theta, a=a, b=b)
        
        try:
            pt.simulate(sim_shot, inplace=True)
        except:
            return -500.0
            
        # 3. è¯„åˆ†
        score = analyze_shot_for_reward(
            shot=sim_shot,
            last_state=last_state_snapshot,
            player_targets=my_targets
        )
        return score

    def decision(self, balls=None, my_targets=None, table=None):
        """ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–æœç´¢æœ€ä½³å‡»çƒå‚æ•°
        
        å‚æ•°ï¼š
            balls: çƒçŠ¶æ€å­—å…¸ï¼Œ{ball_id: Ball}
            my_targets: ç›®æ ‡çƒIDåˆ—è¡¨ï¼Œ['1', '2', ...]
            table: çƒæ¡Œå¯¹è±¡
        
        è¿”å›ï¼š
            dict: å‡»çƒåŠ¨ä½œ {'V0', 'phi', 'theta', 'a', 'b'}
                å¤±è´¥æ—¶è¿”å›éšæœºåŠ¨ä½œ
        """
        if balls is None:
            logger.info("[BayesMCTS] Agent decisionå‡½æ•°æœªæ”¶åˆ°ballså…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚")
            return self._random_action()
        try:
            
            # ä¿å­˜ä¸€ä¸ªå‡»çƒå‰çš„çŠ¶æ€å¿«ç…§ï¼Œç”¨äºå¯¹æ¯”
            last_state_snapshot = {bid: copy.deepcopy(ball) for bid, ball in balls.items()}

            remaining_own = [bid for bid in my_targets if balls[bid].state.s != 4]
            if len(remaining_own) == 0:
                my_targets = ["8"]
                logger.info("[BayesMCTS] æˆ‘çš„ç›®æ ‡çƒå·²å…¨éƒ¨æ¸…ç©ºï¼Œè‡ªåŠ¨åˆ‡æ¢ç›®æ ‡ä¸ºï¼š8å·çƒ")
            
            candidates = []
            cue_ball = balls['cue']
            cue_pos = cue_ball.state.rvw[0]
            R = cue_ball.params.R

            logger.info("[BayesMCTS] æ­£åœ¨ä¸º Player (targets: %s) æœç´¢æœ€ä½³å‡»çƒ...", remaining_own)
            for ball_id in remaining_own:
                obj_pos = balls[ball_id].state.rvw[0]
                for pid, pocket in table.pockets.items():
                    phi_ideal, cut_angle, dist = calculate_ghost_ball_params(cue_pos, obj_pos, pocket.center, R)
                    
                    # åªæœ‰éå¸¸éš¾æ‰“çš„çƒæ‰ä¼šè¢«è¿‡æ»¤ (é˜ˆå€¼ 85åº¦)
                    if abs(cut_angle) > 85: continue
                    
                    candidates.append({
                        'target_id': ball_id,
                        'phi_center': phi_ideal,
                        'cut_angle': cut_angle,
                        'distance': dist
                    })
            
            candidates.sort(key=lambda x: x['cut_angle'])
            top_candidates = candidates[:2]

            top_action = None
            top_score = -float('inf')
            top_base = 0
            top_delta = 0

            for cand in top_candidates:
                # 1.åŠ¨æ€åˆ›å»ºâ€œå¥–åŠ±å‡½æ•°â€ (Wrapper)
                # è´å¶æ–¯ä¼˜åŒ–å™¨ä¼šè°ƒç”¨æ­¤å‡½æ•°ï¼Œå¹¶ä¼ å…¥å‚æ•°

                # å‡ ä½•å…ˆéªŒè§’åº¦
                base_phi = cand['phi_center']
                
                # ä½¿ç”¨ partial ç»‘å®šå‚æ•°ï¼Œç¡®ä¿å˜é‡éš”ç¦»ï¼
                # è¿™æ ·ä¼˜åŒ–å™¨è°ƒç”¨çš„å‡½æ•°å°±åªå‰© (V0, d_phi, theta, a, b) è¿™5ä¸ªå‚æ•°äº†
                target_func = functools.partial(
                    self._evaluate_action,
                    base_phi=base_phi,       # ç»‘å®šå½“å‰çš„å‡ ä½•è§’
                    balls=balls,             # ç»‘å®šå½“å‰çƒçŠ¶æ€
                    table=table,
                    my_targets=my_targets,
                    last_state_snapshot=last_state_snapshot
                )
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                seed = np.random.randint(1e6)
                optimizer = self._create_optimizer(target_func, seed)
                optimizer.maximize(
                    init_points=self.INITIAL_SEARCH,
                    n_iter=self.OPT_SEARCH
                )
                
                best_result = optimizer.max
                best_params = best_result['params']
                best_score = best_result['target']

                final_phi = (float(best_params['phi']) + base_phi) % 360

                action = {
                    'V0': float(best_params['V0']),
                    'phi': final_phi,
                    'theta': float(best_params['theta']),
                    'a': float(best_params['a']),
                    'b': float(best_params['b']),
                }

                if best_score > top_score:
                    top_score = best_score
                    top_action = action
                    top_base = base_phi
                    top_delta = float(best_params['phi'])

            if top_score < 10:
                logger.info("[BayesMCTS] æœªæ‰¾åˆ°å¥½çš„æ–¹æ¡ˆ (æœ€é«˜åˆ†: %.2f)ã€‚ä½¿ç”¨éšæœºåŠ¨ä½œã€‚", top_score)
                return self._random_action()
            
            logger.info(
                "[BayesMCTS] å†³ç­– (å¾—åˆ†: %.2f): V0=%.2f, phi_base=%.2f, phi_delta=%.2f Î¸=%.2f, a=%.3f, b=%.3f",
                top_score,
                top_action['V0'],
                top_base,
                top_delta,
                top_action['theta'],
                top_action['a'],
                top_action['b'],
            )
            return top_action

        except Exception as e:
            logger.error("[BayesMCTS] å†³ç­–æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œä½¿ç”¨éšæœºåŠ¨ä½œã€‚åŸå› : %s", e)
            import traceback
            logger.exception(e)
            return self._random_action()